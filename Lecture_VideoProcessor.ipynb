{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import concurrent.futures\n",
    "from pix2text import Pix2Text\n",
    "from img2table.document import Image\n",
    "from img2table.ocr import SuryaOCR\n",
    "import re\n",
    "import uuid\n",
    "import torch\n",
    "\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, output_dir=\"output_frames\", model_path=\"frozen_east_text_detection.pb\"):\n",
    "        \"\"\"\n",
    "        Инициализация VideoProcessor.\n",
    "\n",
    "        Args:\n",
    "            output_dir (str): Папка для сохранения кадров и графиков.\n",
    "            model_path (str): Путь к модели EAST для детекции текста.\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        self.model_path = model_path\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        # Конфигурация для Pix2Text с локальными путями к моделям\n",
    "        self.total_config = {\n",
    "            \"layout\": {},\n",
    "            \"text_formula\": {\n",
    "                \"languages\": (\"ru\", \"en\"),\n",
    "                \"det_model_path\": \"./models/text_detection_2025_02_28.onnx\",\n",
    "                \"rec_model_path\": \"./models/text_recognition_2025_02_18.onnx\",\n",
    "                \"mfd_model_path\": \"./models/mfd-v20240618.onnx\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        print(f\"Используется устройство: {self.device}\")\n",
    "\n",
    "        self.p2t = Pix2Text.from_config(total_configs=self.total_config, device=self.device)\n",
    "        self.ocr = SuryaOCR(langs=[\"en\", \"ru\"])\n",
    "\n",
    "    def calculate_text_percentage_east_batch(self, frames, min_confidence=0.5):\n",
    "        \"\"\"\n",
    "        Пакетная обработка кадров для вычисления процента текстовой области с помощью EAST.\n",
    "\n",
    "        Args:\n",
    "            frames (list): Список кадров (numpy.ndarray).\n",
    "            min_confidence (float): Порог уверенности для детекции текста.\n",
    "\n",
    "        Returns:\n",
    "            list: Список процентов текстовой области для каждого кадра.\n",
    "        \"\"\"\n",
    "        net = cv2.dnn.readNet(self.model_path)\n",
    "        text_percentages = []\n",
    "\n",
    "        for frame in frames:\n",
    "            orig = frame.copy()\n",
    "            (H, W) = frame.shape[:2]\n",
    "            newW, newH = (320, 320)\n",
    "            rW = W / float(newW)\n",
    "            rH = H / float(newH)\n",
    "            frame = cv2.resize(frame, (newW, newH))\n",
    "            blob = cv2.dnn.blobFromImage(frame, 1.0, (newW, newH),\n",
    "                                         (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            try:\n",
    "                scores, geometry = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"])\n",
    "            except cv2.error as e:\n",
    "                print(f\"Ошибка в net.forward: {e}\")\n",
    "                text_percentages.append(0)\n",
    "                continue\n",
    "            (numRows, numCols) = scores.shape[2:4]\n",
    "            text_area = 0\n",
    "            for y in range(numRows):\n",
    "                for x in range(numCols):\n",
    "                    if scores[0, 0, y, x] < min_confidence:\n",
    "                        continue\n",
    "                    h = geometry[0, 0, y, x]\n",
    "                    w = geometry[0, 1, y, x]\n",
    "                    endX = int((x * 4.0 + geometry[0, 2, y, x]) * rW)\n",
    "                    endY = int((y * 4.0 + geometry[0, 3, y, x]) * rH)\n",
    "                    startX = int(endX - w * rW)\n",
    "                    startY = int(endY - h * rH)\n",
    "                    box_area = max(0, endX - startX) * max(0, endY - startY)\n",
    "                    text_area += box_area\n",
    "            total_area = W * H\n",
    "            text_percentages.append((text_area / total_area) * 100)\n",
    "        return text_percentages\n",
    "\n",
    "    def process_frame_pair(self, prev_gray, frame, frame_index, timestamp, threshold):\n",
    "        \"\"\"\n",
    "        Обработка пары кадров для определения уникальности и процента текста.\n",
    "\n",
    "        Args:\n",
    "            prev_gray (numpy.ndarray): Предыдущий кадр в градациях серого.\n",
    "            frame (numpy.ndarray): Текущий кадр.\n",
    "            frame_index (int): Индекс кадра.\n",
    "            timestamp (str): Временная метка.\n",
    "            threshold (float): Порог SSIM для уникальности.\n",
    "\n",
    "        Returns:\n",
    "            tuple or None: (frame_index, frame, text_percent, timestamp) если кадр уникален и содержит текст, иначе None.\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        score, _ = ssim(prev_gray, gray, full=True)\n",
    "        if score < threshold:\n",
    "            try:\n",
    "                text_percent = self.calculate_text_percentage_east_batch([frame])[0]\n",
    "                if text_percent > 10:\n",
    "                    return (frame_index, frame, text_percent, timestamp)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка обработки кадра {frame_index}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def process_video_segment(self, video_path, start_frame, end_frame, threshold, frame_skip, fps):\n",
    "        \"\"\"\n",
    "        Обработка сегмента видео от start_frame до end_frame.\n",
    "\n",
    "        Args:\n",
    "            video_path (str): Путь к видеофайлу.\n",
    "            start_frame (int): Начальный индекс кадра.\n",
    "            end_frame (int): Конечный индекс кадра.\n",
    "            threshold (float): Порог SSIM для уникальности.\n",
    "            frame_skip (int): Количество пропускаемых кадров.\n",
    "            fps (float): Частота кадров в секунду.\n",
    "\n",
    "        Returns:\n",
    "            list: Список кортежей (frame_index, frame_path, timestamp).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                raise ValueError(f\"Не удалось открыть видеофайл: {video_path}\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "            saved_frames = []\n",
    "            prev_gray = None\n",
    "            frame_count = start_frame\n",
    "            frames_to_process = []\n",
    "\n",
    "            print(f\"Обработка сегмента с кадра {start_frame} по {end_frame}...\")\n",
    "            with tqdm(total=end_frame - start_frame, desc=f\"Сегмент {start_frame}-{end_frame}\", unit=\"кадр\") as pbar:\n",
    "                while frame_count < end_frame:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    timestamp = frame_count / fps\n",
    "                    hours = int(timestamp // 3600)\n",
    "                    minutes = int((timestamp % 3600) // 60)\n",
    "                    seconds = int(timestamp % 60)\n",
    "                    milliseconds = int((timestamp % 1) * 1000)\n",
    "                    time_str = f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}\"\n",
    "                    if frame_count % frame_skip != 0:\n",
    "                        frame_count += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    if prev_gray is not None:\n",
    "                        frames_to_process.append((prev_gray.copy(), frame.copy(), frame_count, time_str))\n",
    "                    prev_gray = gray\n",
    "                    frame_count += 1\n",
    "                    pbar.update(1)\n",
    "            cap.release()\n",
    "\n",
    "            frames = [args[1] for args in frames_to_process]\n",
    "            if frames:\n",
    "                text_percentages = self.calculate_text_percentage_east_batch(frames)\n",
    "            else:\n",
    "                text_percentages = []\n",
    "\n",
    "            for (prev_gray, frame, frame_count, time_str), text_percent in zip(frames_to_process, text_percentages):\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                score, _ = ssim(prev_gray, gray, full=True)\n",
    "                if score < threshold and text_percent > 10:\n",
    "                    frame_filename = f\"frame_{frame_count}_{uuid.uuid4().hex}.jpg\"\n",
    "                    frame_path = os.path.join(self.output_dir, frame_filename)\n",
    "                    cv2.imwrite(frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "                    print(f\"Кадр {frame_count}: Покрытие текстом = {text_percent:.2f}%, Сохранён как {frame_path}\")\n",
    "                    saved_frames.append((frame_count, frame_path, time_str))\n",
    "            return saved_frames\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в сегменте {start_frame}-{end_frame}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def extract_unique_frames(self, video_path, threshold=0.95, frame_skip=48, num_threads=4):\n",
    "        \"\"\"\n",
    "        Извлечение уникальных кадров из видео с значительным текстовым содержимым.\n",
    "\n",
    "        Args:\n",
    "            video_path (str): Путь к видеофайлу.\n",
    "            threshold (float): Порог SSIM для уникальности.\n",
    "            frame_skip (int): Количество пропускаемых кадров (по умолчанию 2 секунды при 24 fps).\n",
    "            num_threads (int): Количество потоков для обработки.\n",
    "\n",
    "        Returns:\n",
    "            list: Список кортежей (frame_index, frame_path, timestamp).\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Не удалось открыть видеофайл: {video_path}\")\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        cap.release()\n",
    "\n",
    "        frames_per_thread = total_frames // num_threads\n",
    "        segments = [\n",
    "            (i * frames_per_thread, min((i + 1) * frames_per_thread, total_frames))\n",
    "            for i in range(num_threads)\n",
    "        ]\n",
    "\n",
    "        saved_frames = []\n",
    "        print(f\"Разделение видео на {num_threads} сегментов: {segments}\")\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            futures = [\n",
    "                executor.submit(\n",
    "                    self.process_video_segment,\n",
    "                    video_path, start, end, threshold, frame_skip, fps\n",
    "                )\n",
    "                for start, end in segments\n",
    "            ]\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures),\n",
    "                               desc=\"Обработка сегментов\"):\n",
    "                saved_frames.extend(future.result())\n",
    "\n",
    "        saved_frames.sort(key=lambda x: x[0])\n",
    "        return saved_frames\n",
    "\n",
    "    def extract_all_formulas(self, text):\n",
    "        \"\"\"\n",
    "        Извлечение всех возможных формул из текста.\n",
    "\n",
    "        Args:\n",
    "            text (str): Текст для извлечения формул.\n",
    "\n",
    "        Returns:\n",
    "            list: Список извлечённых формул в виде строк.\n",
    "        \"\"\"\n",
    "        latex_formulas = re.findall(r'\\$\\$[\\s\\S]*?\\$\\$|\\$[^\\$]*?\\$|\\\\\\[.*?\\\\\\]', text, re.MULTILINE)\n",
    "        additional_candidates = [\n",
    "            line.strip() for line in text.split('\\n')\n",
    "            if any(sym in line for sym in ['=', '+', '-', '*', '^', '_', '\\\\frac', '\\\\sum', '\\\\int', '△'])\n",
    "               and len(line.strip()) > 3\n",
    "               and not line.strip().startswith('Так как')\n",
    "               and not re.match(r'^[a-zA-ZА-Яа-я\\s]+$', line.strip())\n",
    "        ]\n",
    "        all_formulas = list(set(latex_formulas + additional_candidates))\n",
    "        return all_formulas\n",
    "\n",
    "    def extract_text_and_formulas(self, frame_path):\n",
    "        \"\"\"\n",
    "        Извлечение текста и формул из кадра с помощью Pix2Text.\n",
    "\n",
    "        Args:\n",
    "            frame_path (str): Путь к изображению кадра.\n",
    "\n",
    "        Returns:\n",
    "            dict: Словарь с ключами 'text' и 'formulas'.\n",
    "        \"\"\"\n",
    "        text = self.p2t.recognize(frame_path, file_type=\"text_formula\", return_text=True, auto_line_break=True,\n",
    "                                  use_fast=True)\n",
    "        formulas = self.extract_all_formulas(text)\n",
    "        return {'text': text, 'formulas': formulas}\n",
    "\n",
    "    def is_bar_chart(self, edges, img_shape):\n",
    "        \"\"\"\n",
    "        Проверка, содержит ли изображение столбчатую диаграмму.\n",
    "\n",
    "        Args:\n",
    "            edges (numpy.ndarray): Изображение с выделенными краями.\n",
    "            img_shape (tuple): Размеры изображения (высота, ширина).\n",
    "\n",
    "        Returns:\n",
    "            bool: True, если обнаружена столбчатая диаграмма.\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "        return lines is not None and len(lines) > 5\n",
    "\n",
    "    def is_tree_diagram(self, edges, gray_img, img_shape):\n",
    "        \"\"\"\n",
    "        Проверка, содержит ли изображение древовидную диаграмму.\n",
    "\n",
    "        Args:\n",
    "            edges (numpy.ndarray): Изображение с выделенными краями.\n",
    "            gray_img (numpy.ndarray): Изображение в градациях серого.\n",
    "            img_shape (tuple): Размеры изображения (высота, ширина).\n",
    "\n",
    "        Returns:\n",
    "            bool: True, если обнаружена древовидная диаграмма.\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=20, maxLineGap=10)\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        nodes = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if 100 < area < 5000:\n",
    "                peri = cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "                if len(approx) >= 4 or cv2.minEnclosingCircle(contour)[1] > 5:\n",
    "                    nodes.append(contour)\n",
    "        return len(nodes) > 2 and lines is not None and len(lines) > 1\n",
    "\n",
    "    def get_chart_box(self, edges, img_shape):\n",
    "        \"\"\"\n",
    "        Получение ограничивающего прямоугольника области диаграммы.\n",
    "\n",
    "        Args:\n",
    "            edges (numpy.ndarray): Изображение с выделенными краями.\n",
    "            img_shape (tuple): Размеры изображения (высота, ширина).\n",
    "\n",
    "        Returns:\n",
    "            tuple or None: (x, y, w, h) области диаграммы или None, если не найдено.\n",
    "        \"\"\"\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_area = 0\n",
    "        chart_box = None\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 1000:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    chart_box = (x, y, w, h)\n",
    "        return chart_box\n",
    "\n",
    "    def extract_charts(self, frame_path):\n",
    "        \"\"\"\n",
    "        Обнаружение и извлечение диаграмм из кадра.\n",
    "\n",
    "        Args:\n",
    "            frame_path (str): Путь к изображению кадра.\n",
    "\n",
    "        Returns:\n",
    "            list: Список путей к сохранённым изображениям диаграмм.\n",
    "        \"\"\"\n",
    "        img = cv2.imread(frame_path)\n",
    "        if img is None:\n",
    "            return []\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        height, width = img.shape[:2]\n",
    "        chart_paths = []\n",
    "        chart_box = None\n",
    "        if self.is_bar_chart(edges, (height, width)) or self.is_tree_diagram(edges, gray, (height, width)):\n",
    "            chart_box = self.get_chart_box(edges, (height, width))\n",
    "        if chart_box:\n",
    "            x, y, w, h = chart_box\n",
    "            padding = 50\n",
    "            x_new = max(x - padding, 0)\n",
    "            y_new = max(y - padding, 0)\n",
    "            w_new = min(w + 2 * padding, width - x_new)\n",
    "            h_new = min(h + 2 * padding, height - y_new)\n",
    "            chart_img = img[y_new:y_new + h_new, x_new:x_new + w_new]\n",
    "            chart_filename = f\"chart_{uuid.uuid4().hex}.jpg\"\n",
    "            chart_path = os.path.join(self.output_dir, chart_filename)\n",
    "            cv2.imwrite(chart_path, chart_img)\n",
    "            chart_paths.append(chart_path)\n",
    "        return chart_paths\n",
    "\n",
    "    def merge_cells(self, table):\n",
    "        \"\"\"\n",
    "        Объединение ячеек таблицы с одинаковым текстом.\n",
    "\n",
    "        Args:\n",
    "            table: Объект таблицы, содержащий данные о ячейках.\n",
    "\n",
    "        Returns:\n",
    "            list: Список строк таблицы, где одинаковый текст объединён.\n",
    "        \"\"\"\n",
    "        rows = list(table.content.values())\n",
    "        num_rows = len(rows)\n",
    "        num_cols = max(len(row) for row in rows)\n",
    "        merged_table = [\n",
    "            [str(cell.value).replace(\"-\\n\", \"-\").replace(\"\\n\", \" \") if hasattr(cell, 'value') and cell.value else \"\"\n",
    "             for cell in row]\n",
    "            for row in rows\n",
    "        ]\n",
    "        for row in merged_table:\n",
    "            for i in range(len(row) - 1, 0, -1):\n",
    "                if row[i] == row[i - 1]:\n",
    "                    row[i] = \"\"\n",
    "        for col in range(num_cols):\n",
    "            for row in range(num_rows - 1, 0, -1):\n",
    "                if merged_table[row][col] == merged_table[row - 1][col]:\n",
    "                    merged_table[row][col] = \"\"\n",
    "        return merged_table\n",
    "\n",
    "    def table_to_markdown(self, table):\n",
    "        \"\"\"\n",
    "        Преобразование таблицы в формат Markdown.\n",
    "\n",
    "        Args:\n",
    "            table: Объект таблицы.\n",
    "\n",
    "        Returns:\n",
    "            str: Таблица в формате Markdown.\n",
    "        \"\"\"\n",
    "        markdown_output = \"\"\n",
    "        merged_table = self.merge_cells(table)\n",
    "        num_columns = max(len(row) for row in merged_table)\n",
    "        for i, row in enumerate(merged_table):\n",
    "            markdown_output += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "            if i == 0:\n",
    "                markdown_output += \"| \" + \" | \".join([\"---\"] * num_columns) + \" |\\n\"\n",
    "        return markdown_output\n",
    "\n",
    "    def extract_tables(self, frame_path, time_code):\n",
    "        \"\"\"\n",
    "        Извлечение таблиц из изображения и преобразование в Markdown.\n",
    "\n",
    "        Args:\n",
    "            frame_path (str): Путь к изображению.\n",
    "            time_code (str): Временной код для идентификации таблицы.\n",
    "\n",
    "        Returns:\n",
    "            list: Список таблиц в формате Markdown.\n",
    "        \"\"\"\n",
    "        img_document = Image(frame_path)\n",
    "        extracted_tables = img_document.extract_tables(ocr=self.ocr)\n",
    "        markdown_tables = [self.table_to_markdown(table) for table in extracted_tables]\n",
    "        return markdown_tables\n",
    "\n",
    "    def process_video(self, video_path, threshold=0.95, frame_skip=48, num_threads=4):\n",
    "        \"\"\"\n",
    "        Обработка видео для извлечения уникальных кадров, текста, формул, диаграмм и таблиц.\n",
    "\n",
    "        Args:\n",
    "            video_path (str): Путь к видеофайлу.\n",
    "            threshold (float): Порог SSIM для уникальности.\n",
    "            frame_skip (int): Количество пропускаемых кадров.\n",
    "            num_threads (int): Количество потоков.\n",
    "\n",
    "        Returns:\n",
    "            dict: JSON-совместимый словарь с деталями кадров.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        unique_frames = self.extract_unique_frames(video_path, threshold, frame_skip, num_threads)\n",
    "        for frame_index, frame_path, timestamp in unique_frames:\n",
    "            text_formulas = self.extract_text_and_formulas(frame_path)\n",
    "            charts = self.extract_charts(frame_path)\n",
    "            tables = self.extract_tables(frame_path, timestamp)\n",
    "            result[f\"frame_{frame_index}\"] = {\n",
    "                \"frame_index\": frame_index,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"frame_path\": frame_path,\n",
    "                \"text\": text_formulas['text'],\n",
    "                \"formulas\": text_formulas['formulas'],\n",
    "                \"charts\": charts,\n",
    "                \"tables\": tables\n",
    "            }\n",
    "        with open(\"video_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 2025-04-21 23:49:25,798 __init__:71] Using CPU. Note: This module is much faster with a GPU. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/main/Documents/nlp/.venv/lib/python3.12/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "/home/main/Documents/nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Downloading 'README.md' to '/home/main/.pix2text/1.1/table-rec/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.eff050b4d0ff55cb94ffb9aa71d30ad77c440e22.incomplete'\n",
      "Downloading '.gitattributes' to '/home/main/.pix2text/1.1/table-rec/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
      "Downloading 'config.json' to '/home/main/.pix2text/1.1/table-rec/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.5ad600679662798040286d4d17c626cbffddd755.incomplete'\n",
      "Downloading 'model.safetensors' to '/home/main/.pix2text/1.1/table-rec/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.9df416575a3a36ebd0129342d4f597f14d6e5170268f3d52d28584ab4466a501.incomplete'\n",
      "Download complete. Moving file to /home/main/.pix2text/1.1/table-rec/README.md\n",
      "Download complete. Moving file to /home/main/.pix2text/1.1/table-rec/.gitattributes\n",
      "Fetching 5 files:  20%|██        | 1/5 [00:00<00:01,  2.48it/s]Download complete. Moving file to /home/main/.pix2text/1.1/table-rec/config.json\n",
      "Downloading 'preprocessor_config.json' to '/home/main/.pix2text/1.1/table-rec/.cache/huggingface/download/PYH5dHjks7Ei0Yd3X0Z8xIwsCNQ=.f8a7f45eb6b981d5e410303665181f0f3e34d4fa.incomplete'\n",
      "Download complete. Moving file to /home/main/.pix2text/1.1/table-rec/preprocessor_config.json\n",
      "Download complete. Moving file to /home/main/.pix2text/1.1/table-rec/model.safetensors\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:10<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/main/.pix2text/1.1/table-rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading text_detection model...: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading text_recognition model...:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    processor = VideoProcessor(\n",
    "        output_dir=\"output_frames\",\n",
    "        model_path=\"frozen_east_text_detection.pb\"\n",
    "    )\n",
    "    \n",
    "    video_path = \"5c197850a4db3438f0e5cbf1.mp4\"\n",
    "    threshold = 0.95\n",
    "    frame_skip = 48\n",
    "    num_threads = 4\n",
    "    \n",
    "    result = processor.process_video(\n",
    "        video_path=video_path,\n",
    "        threshold=threshold,\n",
    "        frame_skip=frame_skip,\n",
    "        num_threads=num_threads\n",
    "    )\n",
    "    \n",
    "    print(\"Обработка завершена. Результаты сохранены в output_frames и video_analysis.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
